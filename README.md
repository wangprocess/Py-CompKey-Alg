Py-CompKey-dev

竞争性关键词的搜索引擎开发

部署运行：
	1、首先你需要老师提供的或者网上下载的百度的某一年的搜索记录，这里用到的是user_tag_query.10W.TRAIN文件
	2、终端执行pip install -r requirement下载依赖
	3、按jupyter的代码块顺序运行代码

文件结构：
	1、ana_eval_sparse.py文件是用来探究词向量相似度的准确率的，没有实际意义，与项目关系不大
	2、experiment1.ipynb文件是进行系统开发的第一版，是未进行优化的代码，是核心代码
	3、experiment2.ipynb文件是优化后的代码，提高竞争性关键词计算的性能
	4、stop_words.txt是所用到的停语词列表
	
运行核心代码后的文件结构：
PY-comp-key-dev
├─agencywords_compkey  # 对每一个种子关键词，通过中介关键词来查找竞争性关键词
│  ├─compkey_words  # 竞争性关键词结果
│  ├─jieba_search_info  # jieba分词后的结果
│  ├─search_info  # 从所有搜索记录中找出含有中介关键词的搜索记录
│  └─stop_words_filter  # 停语词过滤后的结果
│  
├─comp  # 算出每个种子关键词的总的comp度，也就是西格玛求和后的comp度，对每一个中介关键词进行加权
│  
├─comp_plus  # 对comp文件夹中的结果进一步过滤，去掉中介关键词，探究出来的问题，进行过滤，所以这是最终文件
│ 
├─result  # 每个种子关键词对应的在中介关键词a下的comp度
│  
├─seedwords_agencywords  #通过种子关键词查找中介关键词
│  ├─agency_words  # 中介关键词结果
│  ├─jieba_search_info  # jieba分词后的结果
│  ├─search_info  # 从所有搜索记录中找出含有种子关键词的搜索记录
│  └─stop_words_filter  # 停语词过滤后的结果
│  
├─all_logs.txt  # 对原始搜索记录user_tag_query.10W.TRAIN文件处理后的所有搜索记录
├─jieba_words.txt  # jieba分词后的输出文件
├─re_filter.txt  # 正则表达式过滤后的输出文件，去除不合理的网址、乱码等
├─experiment1.ipynb  # 核心代码
├─experiment2.ipynb  # 优化后的代码
├─requirement  # 依赖文件
├─seeds_keyvalue.txt # 对jieba分词后的数据进行统计
├─stop_words.txt # 停语词文件，过滤的参考文件
└─stopwords_filter.txt # 停语词过滤后输出的文件




第一阶段：
	完成数据的预处理和清洗工作
	根据关键词的出现频率来选取种子关键词
	通过种子关键词来获取中介关键词
	解决了文件的编码获取问题
	完成了代码的优化处理
	进行了分词工具的横向对比
	
第二阶段：
	首先，在第一步的获取中介关键词的基础上，进行sa/s的计算，算出中介关键词的权重
	然后，进行备选竞争关键词的提取，使用"提取搜索信息-jieba分词-停语词清洗-统计出现次数“的方式,将一些竞争性关键词存起来
	接下来，计算每一个竞争性关键词的comp竞度，这里的comp度是在中介关键词a的基础上的comp，不是最后的comp
	最后，计算总的comp度，将每一个竞争性关键词在a上的comp乘上a的权重，求和后得出总的comp度，将其按从大到小排序，取top5出来
	基于上述的计算，将竞争性关键词的comp度和中介关键词的权重进行绘图，使用plot绘出
	
	创新点：
		- 从机器学习中得到灵感，进行权重的平滑，降低突发式搜索的影响（2016问题）公式： alpha * avg(weight) + (1 - alpha) * weight
		- 针对种子关键词和竞争性关键词不同时出现在中介关键词中，或者说种子关键词、中介关键词、竞争关键词不能互相包含，基于此，
		  进行了词义相似度的判断，使用spacy进行判断，也就是不仅不互相包含，也不十分相似；在此过程中探究了word2vec词向量融入和纯使用spacy的区别，由于时间选择了spacy
		- 还探究了在公式的带入计算时，搜索量要统计的是词在一句话中出现就算一次，还是jieba分词后，词的出现次数
		- 还发现了一个问题，就是即使在已经剔除了中介关键词和竞争性关键词同时出现的情况下，还会出现，在最后的竞争性关键词列表中，
		  会有中介关键词的出现，这是因为关联搜索的问题，也就是某一个中介关键词和另一个中介关键词经常联合搜索，会导致在中介关键词A下，
		  中介关键词B的comp度比较大，最后出现在总的comp的前列，这不是没有剔除不同时出现的情况，而是特殊的情况，所以应该剔除